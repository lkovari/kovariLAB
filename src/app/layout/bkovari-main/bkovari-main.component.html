<section class="bkovari-page" fxLayout="column" fxFlexAlign="stretch">
  <div fxFlexAlign="center" class="align-welcome">
    <p>Bálint Kővári's page</p>
    <div>
      <label class="pub-item-title">Publications</label>
      <div class="list-alignment">
        <ul>
          <li>2020
            <ul>
              <li class="li-separator">Published by IEEE Access <a href="https://ieeexplore.ieee.org/document/9163347">
                  Reinforcement Learning based Control Design for a Floating Piston Pneumatic Gearbox Actuator
                </a>
                <div>
                  <div class="pub-subtitle">Abstract:</div>
                  Electro-pneumatic actuators play an essential role in various areas of the industry, including
                  heavy-duty vehicles. This article deals with the control problem of an Automatic Manual Transmission,
                  where the actuator of the system is a double-acting floating-piston cylinder, with dedicated
                  inner-position. During the control design of electro-pneumatic cylinders, one must implement a
                  set-valued control on a nonlinear system, when, as in the present case, non-proportional valves
                  provide the airflow. As both the system model itself and the qualitative control goals can be
                  formulated as a Partially Observable Markov Decision Process, Machine learning frameworks are a
                  conspicuous choice for handling such control problems. To this end, six different solutions are
                  compared in the article, of which a new agent named PG-MCTS, using a modified version of the "Upper
                  Confidence bound for Trees" algorithm, is also presented. The performance and strategic choice
                  comparison of the six methods are carried out in a simulation environment. Validation tests performed
                  on an actual transmission system and implemented on an automotive control unit to prove the
                  applicability of the concept. In this case, a Policy Gradient agent, selected by implementation and
                  computation capacity restrictions. The results show that the presented methods are suitable for the
                  control of floating-piston cylinders and can be extended to other fluid mechanical actuators, or even
                  different set-valued nonlinear control problems.
                </div>
              </li>
            </ul>
          </li>
          <li>2019
            <ul>
              <li class="li-separator">Published by ResearchGate <a
                  href="https://www.researchgate.net/profile/Henrietta_Lengyel/publication/342888632_Potential_Weak_Points_of_Environment_Sensors_in_Autonomous_Vehicles/links/5f0c2b3e299bf1074452d0c8/Potential-Weak-Points-of-Environment-Sensors-in-Autonomous-Vehicles.pdf#page=417">
                  Highway behaviour training through learning based state choice model
                </a>
                <div>
                  <div class="pub-subtitle">Abstract:</div>
                  Automated highway driving solutions are reaching the commercially available vehicles, though with
                  restricted functionalities. The research presents a mixed simulation model, where the behavior
                  planning of a vehicle can be designed with interactive traffic environment, the traffic is modelled
                  with classic microscopic approach, though the vehicle to be controlled uses more complex model. The
                  control of the vehicle is based on a hierarchical state machine approach, where the model can choose
                  from different basic behavior schemes, like lane keeping, lane changing etc. with underlying low-level
                  control for all states. The paper shows the performance of the classic state choice models and
                  compares it to a machine learning based approach, where the state transition decisions are controlled
                  by a neural network structure.
                </div>
              </li>
              <li class="li-separator">Published by KITT UNI ÓBUDA <a
                  href="http://kitt.uni-obuda.hu/mmaws/2019/pages/program/papers/Paper_17_Kovari_B_Becsi_T_Szalay_Zs_IFFK_2019.pdf">
                  Megerősítéses tanulás és MCTS alkalmazása trajektóriakövetésben
                </a>
                <div>
                  <div class="pub-subtitle">Kivonat:</div>
                  A publikáció bemutatja a mesterséges intelligencia új területét megtestesítő megerősítéses tanulás
                  -Q-learning és Policy Gradient- és klasszikus keresés és tervezés alapú megközelítéseket,
                  járműirányítási
                  feladatok megoldására. A felvetés célja, hogy megtaláljuk az eredmények összehasonlításán keresztül az
                  egyes irányzatok alkalmazásspecifikus előnyeit és hátrányait. A feladat egy kinematikai bicikli modell
                  trajektória követésének megvalósítása. A probléma absztrahálásához magasszintű szenzorinformációkat
                  használunk, a trajektória követési feladat meghatározásához pedig egy kiértékelő függvényt hozunk
                  létre,
                  amely a jármű helyzetét vizsgálja a pálya viszonylatában minden egyes mintavételezés során. Az
                  algoritmusok eredményeinek összehasonlítását, a trajektória követés stabilitása és annak minősége
                  alapján valósítjuk meg.
                  .
                </div>
              </li>
            </ul>
          </li>
          <li>2018
            <ul>
              <li class="li-separator">Published by IEEE Explore <a
                  href="https://ieeexplore.ieee.org/abstract/document/9065122">
                  Policy Gradient Based Control of a Pneumatic Actuator Enhanced with Monte Carlo Tree Search
                </a>
                <div>
                  <div class="pub-subtitle">Abstract:</div>
                  This paper presents a synergy of the Monte-Carlo tree search (MCTS) and a reinforcement learning (RL)
                  based control strategy to achieve the position control of an electropneumatic gearbox actuator.
                  Besides tracking the reference signal, there are qualitative requirements regarding the switching time
                  and the overshoot, and there is also a necessity of reliable behavior in a wide range of operating
                  conditions. By utilizing the domain-specific knowledge of a trained agent, the direction of the tree
                  search can be controlled, hence the quality of the RL control can be further enhanced by the
                  robustness of the MCTS algorithm.
                </div>
              </li>
            </ul>
          </li>
        </ul>
      </div>
    </div>
  </div>
</section>